% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ingestion.R
\name{ingest_surveys}
\alias{ingest_surveys}
\title{Ingest WCS and WF Catch Survey Data}
\usage{
ingest_surveys(log_threshold = logger::DEBUG)
}
\arguments{
\item{log_threshold}{The logging threshold to use. Default is logger::DEBUG.
See \code{logger::log_levels} for available options.}
}
\value{
None (invisible). The function performs its operations for side effects:
\itemize{
\item Creates parquet files locally
\item Uploads files to configured cloud storage
\item Generates logs of the process
}
}
\description{
This function handles the automated ingestion of fish catch survey data from both WCS
and WF sources through Kobo Toolbox. It performs the following operations:
\enumerate{
\item Downloads the survey data from Kobo Toolbox
\item Processes and formats the data
\item Uploads the processed files to configured cloud storage locations
}
}
\details{
The function requires specific configuration in the \code{conf.yml} file with the following structure:

\if{html}{\out{<div class="sourceCode yaml">}}\preformatted{surveys:
  wcs_surveys:
    raw_surveys:
      file_prefix: "wcs_raw_data"     # Prefix for output files
      asset_id: "xxxxx"               # Kobo Toolbox asset ID
      username: "user@example.com"    # Kobo Toolbox username
      password: "password123"         # Kobo Toolbox password
  wf_surveys:
    raw_surveys:
      file_prefix: "wf_raw_data"
      asset_id: "yyyyy"
      username: "user2@example.com"
      password: "password456"
storage:
  gcp:                               # Storage provider name
    key: "google"                    # Storage provider identifier
    options:
      project: "project-id"          # Cloud project ID
      bucket: "bucket-name"          # Storage bucket name
      service_account_key: "path/to/key.json"
}\if{html}{\out{</div>}}

The function processes both WCS and WF surveys sequentially, with separate logging
for each step. For each survey:
\itemize{
\item Downloads data using the \code{retrieve_surveys()} function
\item Converts the data to parquet format
\item Uploads the resulting files to all configured storage providers
}

Error handling is managed through the logger package, with informative messages
at each step of the process.
}
\examples{
\dontrun{
# Run with default debug logging
ingest_surveys()

# Run with info-level logging only
ingest_surveys(logger::INFO)
}

}
\seealso{
\itemize{
\item \code{\link[=retrieve_surveys]{retrieve_surveys()}} for details on the survey retrieval process
\item \code{\link[=upload_cloud_file]{upload_cloud_file()}} for details on the cloud upload process
}
}
\keyword{ingestion}
\keyword{workflow}
