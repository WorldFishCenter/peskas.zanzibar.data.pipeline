[{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement [INSERT CONTACT METHOD]. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https:// www.contributor-covenant.org/translations.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to peskas.kenyar.data.pipeline","title":"Contributing to peskas.kenyar.data.pipeline","text":"outlines propose change peskas.kenyar.data.pipeline. detailed info contributing , tidyverse packages, please see development contributing guide.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to peskas.kenyar.data.pipeline","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to peskas.kenyar.data.pipeline","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed).","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to peskas.kenyar.data.pipeline","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"WorldFishCenter/peskas.kenyar.data.pipeline\", fork = TRUE). Install development dependences devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to peskas.kenyar.data.pipeline","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to peskas.kenyar.data.pipeline","text":"Please note peskas.kenyar.data.pipeline project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) 2021 WorldFish  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. peskas.timor.data.pipeline Copyright (C) 2021 WorldFish This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with peskas.kenya.data.pipeline","title":"Getting help with peskas.kenya.data.pipeline","text":"Thanks using peskas.kenya.data.pipeline! filing issue, places explore pieces put together make process smooth possible.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/SUPPORT.html","id":"make-a-reprex","dir":"","previous_headings":"","what":"Make a reprex","title":"Getting help with peskas.kenya.data.pipeline","text":"Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! section tidyverse site.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/SUPPORT.html","id":"where-to-ask","dir":"","previous_headings":"","what":"Where to ask?","title":"Getting help with peskas.kenya.data.pipeline","text":"Armed reprex, next step figure ask. ’s question: start community.rstudio.com, /StackOverflow. people answer questions. ’s bug: ’re right place, file issue. ’re sure: let community help figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/SUPPORT.html","id":"what-happens-next","dir":"","previous_headings":"","what":"What happens next?","title":"Getting help with peskas.kenya.data.pipeline","text":"efficient possible, development tidyverse packages tends bursty, shouldn’t worry don’t get immediate response. Typically don’t look repo sufficient quantity issues accumulates, ’s burst intense activity focus efforts. makes development efficient avoids expensive context switching problems, cost taking longer get back . process makes good reprex particularly important might multiple months initial report start working . can’t reproduce bug, can’t fix !","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lorenzo Longobardi. Author, maintainer. WorldFish. Copyright holder.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Longobardi L (2025). peskas.zanzibar.data.pipeline: Functions Implement Zanzibar Small Scale Fisheries Data Pipeline. R package version 2.4.0, https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/.","code":"@Manual{,   title = {peskas.zanzibar.data.pipeline: Functions to Implement the Zanzibar Small Scale Fisheries Data Pipeline},   author = {Lorenzo Longobardi},   year = {2025},   note = {R package version 2.4.0},   url = {https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/}, }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/index.html","id":"peskaszanzibardatapipeline","dir":"","previous_headings":"","what":"Functions to Implement the Zanzibar Small Scale Fisheries Data Pipeline","title":"Functions to Implement the Zanzibar Small Scale Fisheries Data Pipeline","text":"goal peskas.zanzibar.data.pipeline implement, deploy, execute data modelling pipelines underpin Zanzibar, small-scale fisheries analytics Zanzibar.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/index.html","id":"the-pipeline-is-an-r-package","dir":"","previous_headings":"","what":"The pipeline is an R package","title":"Functions to Implement the Zanzibar Small Scale Fisheries Data Pipeline","text":"peskas.zanzibar.data.pipeline structured R package makes easier write production-grade software. Specifically, structuring code R package allows us : better handle system package dependencies, forces us split code functions, makes easier document code, makes easier test code make heavy use tidyverse style conventions usethis package automate tasks project setup deployment. information rationale structuring pipeline package check Chapter 3 Engineering Production-Grade Shiny Apps. book focused Shiny applications rationale also applies data pipelines production-ready code general. best place learn package development probably R packages book Hadley Wickham Jenny Brian.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/index.html","id":"the-pipeline-runs-on-github-actions","dir":"","previous_headings":"","what":"The pipeline runs on Github Actions","title":"Functions to Implement the Zanzibar Small Scale Fisheries Data Pipeline","text":"step pipeline defined function package, functions deployed integrated using GitHub Actions. allow us take advantages best practices continous development integration (CD/CI) automatically link code execution. However, workflow functions work almost scripts don’t take parameters used side effects. job pipeline defined workflow file: .github/workflows/data-pipeline.yaml can seen figure . Note additional workflows exist test package multiple environments build documentation website.  figure illustrate jobs part pipeline workflow. Note implemented yet. Generally, artifacts produced job stored cloud storage container retrieved cloud storage next job pipeline. storing job’s artifacts versioned using function add_version(), generally includes timestamp commit sha. approach allow us trace artifact unique run pipeline. retrieving jobs can call cloud_object_name() obtain latest specific version artifact.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/index.html","id":"environment-parameters-are-specified-in-the-config-file","dir":"","previous_headings":"","what":"Environment parameters are specified in the config file","title":"Functions to Implement the Zanzibar Small Scale Fisheries Data Pipeline","text":"parameters determine pipeline run specified inst/conf.yml. file can accessed using system.file(\"conf.yml\",package=\"peskas.zanzibar.data.pipeline\"). Using file, opposed , example, including code, allows us easily switch parameters depending environment. use config package read configuration file. use three different environments (see ). determine environment use, config package checks environment variable R_CONFIG_ACTIVE. Remote development environment (default): development environment “default” configuration. environment used code running cloud One characteristic environment uses cloud storage buckets differ real application uses. makes ideal test code pipeline ’s deployed production. environment designed run cloud, indicates API tokens authentication files read environment variables. works well code runs GitHub Actions, workflow instructions read authentication details GitHub secrets passes R environment variables. Local development environment: “local” environment similar default environment used development therefore uses resources ideal testing code. main difference authentication information read environment variables local files. Specifically authentication files live directory called auth never committed git. possible run Sys.setenv(R_CONFIG_ACTIVE=\"local\") R console ensure local environment activated next time conf.yml read. even easier alternative add key-value pair R_CONFIG_ACTIVE=local .Renviron file project directory. Production environment: production environment similar default environment ’s designed run cloud read authentication details cloud. differs uses cloud resources used exclusively production things tested . environment active R_CONFIG_ACTIVE=production; environment variable passed pipeline workflow file code executes “main” git branch.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/index.html","id":"we-use-docker-containers","dir":"","previous_headings":"","what":"We use docker containers","title":"Functions to Implement the Zanzibar Small Scale Fisheries Data Pipeline","text":"use docker containers make easier run develop code. Development: use main Dockerfile development. ’s based rocker/geospatial image spins RStudio server instance quite large number packages. start instance container can simply go project’s directory run docker-compose -d --build terminal console. Production: use Dockerfile.prod run code production. image based lightweight version R installs required packages. first job pipeline builds container steps use run code. allow us run code environment regardless cloud computing infrastructure runs .","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/index.html","id":"logging","dir":"","previous_headings":"","what":"Logging","title":"Functions to Implement the Zanzibar Small Scale Fisheries Data Pipeline","text":"use logger package log events production.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/add_validation_flags.html","id":null,"dir":"Reference","previous_headings":"","what":"Add validation flags to catch data — add_validation_flags","title":"Add validation flags to catch data — add_validation_flags","text":"Adds quality control flags based predefined thresholds rules. Flag descriptions: 1: Number fishers 0 2: Catch negative 3: Catch null despite group_catch non-NULL 4: Catch 0 despite group_catch non-NULL 5: Number buckets high (> 150) 6: Bucket > 40kg 7: Small pelagic individual weight > 10kg 8: Individual weight > 250kg 9: Number fishers high (>70) non-ring nets","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/add_validation_flags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add validation flags to catch data — add_validation_flags","text":"","code":"add_validation_flags(catch_data)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/add_validation_flags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add validation flags to catch data — add_validation_flags","text":"catch_data Processed catch data","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/add_validation_flags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add validation flags to catch data — add_validation_flags","text":"dataframe validation flags added","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/add_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Add timestamp and sha string to a file name — add_version","title":"Add timestamp and sha string to a file name — add_version","text":"alternative version data name using sha (unique identifier) code using generate process data time data generated processed. function adds information, version identifier, file name (character string)","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/add_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add timestamp and sha string to a file name — add_version","text":"","code":"add_version(filename, extension = \"\", sha_nchar = 7, sep = \"__\")"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/add_version.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add timestamp and sha string to a file name — add_version","text":"filename Path sans extension file version extension Extension file sha_nchar Number characters SHA use version identifier sep Characters separating version identifier file name","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/add_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add timestamp and sha string to a file name — add_version","text":"character string file name version identifier","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/add_version.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add timestamp and sha string to a file name — add_version","text":"SHA information retrieved using git2r::sha. code running context aware git repository (example code running inside container) function attempts get sha environment variable GITHUB_SHA. methods fail, sha versioning added.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/add_version.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add timestamp and sha string to a file name — add_version","text":"","code":"if (git2r::in_repository()) {   add_version(\"my_file\", \"csv\") } #> [1] \"my_file__20250408191338_da3c69d__.csv\""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/aggregate_survey_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate survey data and calculate metrics — aggregate_survey_data","title":"Aggregate survey data and calculate metrics — aggregate_survey_data","text":"Aggregates catch data survey level calculates key fisheries metrics including total catches, revenues, effort-based indicators. function: Aggregates catches revenue survey Joins trip information Calculates effort-based metrics (CPUE, RPUE) Adjusts fisher counts multiple boats applicable","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/aggregate_survey_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate survey data and calculate metrics — aggregate_survey_data","text":"","code":"aggregate_survey_data(catch_price_table, trips_info)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/aggregate_survey_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate survey data and calculate metrics — aggregate_survey_data","text":"catch_price_table dataframe containing catch data calculated prices trips_info dataframe containing trip-level information","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/aggregate_survey_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate survey data and calculate metrics — aggregate_survey_data","text":"dataframe aggregated survey data containing: Survey metadata (ID, date, location, habitat) Vessel gear information Total catches revenue Effort-based metrics (CPUE, RPUE) Nested catch composition data","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/aggregate_survey_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aggregate survey data and calculate metrics — aggregate_survey_data","text":"Calculated metrics include: CPUE (Catch Per Unit Effort): kg/fisher/day RPUE (Revenue Per Unit Effort): TZS/fisher/day","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch","text":"Calculates total catch weight using either length-weight relationships bucket measurements. function prioritizes length-based calculations available, falling back bucket-based measurements length data missing. Octopus (OCZ), function converts total length (TL) mantle length (ML) dividing TL 5.5 applying length-weight formula. accounts species-specific differences body morphology.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch","text":"","code":"calculate_catch(catch_data = NULL, lwcoeffs = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch","text":"catch_data data frame containing catch information columns: submission_id - Unique identifier catch n_catch - Number catch events catch_taxon - FAO 3-alpha code individuals - Number individuals (length-based calculations) length - Length measurement cm n_buckets - Number buckets weight_bucket - Weight per bucket kg lwcoeffs data frame containing length-weight coefficients columns: catch_taxon - FAO 3-alpha code a_6 - 60th percentile parameter '' b_6 - 60th percentile parameter 'b'","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch","text":"tibble following columns: submission_id - Unique identifier catch n_catch - Number catch events catch_taxon - FAO 3-alpha code individuals - Number individuals length - Length measurement cm n_buckets - Number buckets weight_bucket - Weight per bucket kg catch_kg - Total catch weight kg","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch","text":"function calculates catch weight using two methods: Length-based calculation: W = * L^b * N / 1000 : W total weight kg b length-weight relationship coefficients (75th percentile) L length cm N number individuals Bucket-based calculation: W = n_buckets * weight_bucket : W total weight kg n_buckets number buckets weight_bucket weight per bucket kg final catch_kg uses length-based calculation available, falling back bucket-based calculation length data missing.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch","text":"Length-based calculations use 75th percentile length-weight coefficients weights returned kilograms NA values returned neither calculation method possible","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch","text":"","code":"if (FALSE) { # \\dontrun{ # Calculate catch weights catch_weights <- calculate_catch(   catch_data = catch_data,   lwcoeffs = length_weight_coeffs ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch_revenue.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate catch revenue from validated data — calculate_catch_revenue","title":"Calculate catch revenue from validated data — calculate_catch_revenue","text":"Calculates revenue based catch weights market prices. function handles missing prices hierarchical approach: Uses direct match available Falls back group median price direct match missing Uses overall median price group median unavailable","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch_revenue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate catch revenue from validated data — calculate_catch_revenue","text":"","code":"calculate_catch_revenue(validated, market_table)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch_revenue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate catch revenue from validated data — calculate_catch_revenue","text":"validated dataframe validated catch data containing weights taxonomic information market_table dataframe containing market price information species group family","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch_revenue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate catch revenue from validated data — calculate_catch_revenue","text":"dataframe calculated revenues, including: Survey catch identification Catch details (date, vessel, gear, fishers) Taxonomic information Adjusted catch weights Calculated revenue TZS","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/calculate_catch_revenue.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate catch revenue from validated data — calculate_catch_revenue","text":"function also: Adjusts catch weights based number elements applicable Aggregates catches survey catch number level Calculates total revenue TZS (Tanzanian Shillings)","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_object_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Full Name of Versioned Cloud Object — cloud_object_name","title":"Retrieve Full Name of Versioned Cloud Object — cloud_object_name","text":"Gets full name(s) object(s) cloud storage matching specified prefix, version, file extension.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_object_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Full Name of Versioned Cloud Object — cloud_object_name","text":"","code":"cloud_object_name(   prefix,   version = \"latest\",   extension = \"\",   provider,   exact_match = FALSE,   options )"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_object_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Full Name of Versioned Cloud Object — cloud_object_name","text":"prefix string indicating object's prefix. version string specifying version (\"latest\" specific version string). extension file extension filter . empty string (\"\") includes extensions. provider character string specifying cloud provider (\"gcs\" \"aws\"). exact_match logical indicating whether match prefix exactly. options named list provider-specific options including bucket authentication details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_object_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Full Name of Versioned Cloud Object — cloud_object_name","text":"vector names objects matching criteria.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_object_name.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve Full Name of Versioned Cloud Object — cloud_object_name","text":"GCS, options list include: bucket: bucket name. service_account_key: authentication JSON contents, previously authenticated.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_object_name.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Full Name of Versioned Cloud Object — cloud_object_name","text":"","code":"if (FALSE) { # \\dontrun{ authentication_details <- readLines(\"path/to/json_file.json\") cloud_object_name(   \"prefix\",   \"latest\",   \"json\",   \"gcs\",   list(service_account_key = authentication_details, bucket = \"my-bucket\") ) #' } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_storage_authenticate.html","id":null,"dir":"Reference","previous_headings":"","what":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","title":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","text":"function primarily used internally functions establish authentication specified cloud providers Google Cloud Services (GCS) Amazon Web Services (AWS).","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_storage_authenticate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","text":"","code":"cloud_storage_authenticate(provider, options)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_storage_authenticate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","text":"provider character string specifying cloud provider (\"gcs\" \"aws\"). options named list options specific cloud provider (see details).","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_storage_authenticate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","text":"GCS, options list must include: service_account_key: contents authentication JSON file Google Project. function wraps googleCloudStorageR::gcs_auth() handle GCS authentication.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/cloud_storage_authenticate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","text":"","code":"if (FALSE) { # \\dontrun{ authentication_details <- readLines(\"path/to/json_file.json\") cloud_storage_authenticate(\"gcs\", list(service_account_key = authentication_details)) #' } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_cloud_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Object from Cloud Storage — download_cloud_file","title":"Download Object from Cloud Storage — download_cloud_file","text":"Downloads object cloud storage local file.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_cloud_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Object from Cloud Storage — download_cloud_file","text":"","code":"download_cloud_file(name, provider, options, file = name)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_cloud_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Object from Cloud Storage — download_cloud_file","text":"name name object storage bucket. provider character string specifying cloud provider (\"gcs\" \"aws\"). options named list provider-specific options including bucket authentication details. file (Optional) local path save downloaded object. specified, object name used.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_cloud_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Object from Cloud Storage — download_cloud_file","text":"path downloaded file.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_cloud_file.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Download Object from Cloud Storage — download_cloud_file","text":"GCS, options list include: bucket: name bucket object downloaded. service_account_key: authentication JSON contents, previously authenticated.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_cloud_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Object from Cloud Storage — download_cloud_file","text":"","code":"if (FALSE) { # \\dontrun{ authentication_details <- readLines(\"path/to/json_file.json\") download_cloud_file(   \"object_name.json\",   \"gcs\",   list(service_account_key = authentication_details, bucket = \"my-bucket\"),   \"local_path/to/save/object.json\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_parquet_from_cloud.html","id":null,"dir":"Reference","previous_headings":"","what":"#' Download Parquet File from Cloud Storage — download_parquet_from_cloud","title":"#' Download Parquet File from Cloud Storage — download_parquet_from_cloud","text":"function handles process downloading parquet file cloud storage reading memory.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_parquet_from_cloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"#' Download Parquet File from Cloud Storage — download_parquet_from_cloud","text":"","code":"download_parquet_from_cloud(prefix, provider, options)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_parquet_from_cloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"#' Download Parquet File from Cloud Storage — download_parquet_from_cloud","text":"prefix file prefix path cloud storage provider cloud storage provider key options Cloud storage provider options","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_parquet_from_cloud.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"#' Download Parquet File from Cloud Storage — download_parquet_from_cloud","text":"tibble containing data parquet file","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/download_parquet_from_cloud.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"#' Download Parquet File from Cloud Storage — download_parquet_from_cloud","text":"","code":"if (FALSE) { # \\dontrun{ raw_data <- download_parquet_from_cloud(   prefix = conf$ingestion$koboform$catch$legacy$raw,   provider = conf$storage$google$key,   options = conf$storage$google$options ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/expand_taxa.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand Taxonomic Vectors into a Data Frame — expand_taxa","title":"Expand Taxonomic Vectors into a Data Frame — expand_taxa","text":"Converts vector species identifiers detailed data frame containing taxonomic classification. identifier follow format 'family_genus_species', expanded include comprehensive taxonomic details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/expand_taxa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand Taxonomic Vectors into a Data Frame — expand_taxa","text":"","code":"expand_taxa(data = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/expand_taxa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand Taxonomic Vectors into a Data Frame — expand_taxa","text":"data vector species identifiers formatted 'family_genus_species'. provided, function return error.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/expand_taxa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand Taxonomic Vectors into a Data Frame — expand_taxa","text":"data frame row corresponds species, enriched taxonomic classification information including family, genus, species, additional taxonomic ranks.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/expand_taxa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expand Taxonomic Vectors into a Data Frame — expand_taxa","text":"function splits species identifier constituent parts, replaces underscores spaces readability, retrieves taxonomic classification GBIF database using taxize package.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/expand_taxa.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Expand Taxonomic Vectors into a Data Frame — expand_taxa","text":"Requires internet access fetch data GBIF database. accuracy results depends correct formatting input data availability taxonomic data GBIF database.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/expand_taxa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand Taxonomic Vectors into a Data Frame — expand_taxa","text":"","code":"if (FALSE) { # \\dontrun{ species_vector <- c(\"lutjanidae_lutjanus_spp\", \"scaridae_spp\", \"acanthuridae_naso_hexacanthus\") expanded_data <- expand_taxa(species_vector) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Export Processed Fisheries Data to MongoDB — export_data","title":"Export Processed Fisheries Data to MongoDB — export_data","text":"Processes validated survey data generate summary metrics exports MongoDB collections. function calculates three main types metrics: Monthly CPUE RPUE metrics landing site Gear-specific metrics landing site habitat Taxa proportions landing site","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export Processed Fisheries Data to MongoDB — export_data","text":"","code":"export_data(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export Processed Fisheries Data to MongoDB — export_data","text":"log_threshold logging level threshold logger package (e.g., DEBUG, INFO) See logger::log_levels available options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export Processed Fisheries Data to MongoDB — export_data","text":"None (invisible). function performs operations side effects: Processes survey data summary metrics Uploads results MongoDB collections Generates logs process","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Export Processed Fisheries Data to MongoDB — export_data","text":"function performs following operations: Filters landing sites >75% missing CPUE data Calculates monthly median CPUE RPUE values Processes gear-specific metrics, excluding gears spaces names \"\" category Computes taxa proportions, grouping taxa <5% representation \"Others\" Uploads processed data specified MongoDB collections metrics calculated include: CPUE (Catch Per Unit Effort) RPUE (Revenue Per Unit Effort) Catch proportions taxa Exported collections: Monthly metrics: Time series CPUE RPUE landing site Gear metrics: CPUE RPUE gear type, habitat, landing site Taxa proportions: Percentage contribution taxa total catch landing site","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export Processed Fisheries Data to MongoDB — export_data","text":"","code":"if (FALSE) { # \\dontrun{ # Export data with default debug logging export_data()  # Export with info-level logging only export_data(logger::INFO) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_wf_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Export WorldFish Survey Data — export_wf_data","title":"Export WorldFish Survey Data — export_wf_data","text":"Processes validated survey data WorldFish sources, filtering flagged submissions generating two key datasets: Indicators dataset aggregated catch metrics Taxa dataset species-specific catch information","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_wf_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export WorldFish Survey Data — export_wf_data","text":"","code":"export_wf_data(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_wf_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export WorldFish Survey Data — export_wf_data","text":"log_threshold logging level threshold logger package (e.g., DEBUG, INFO) See logger::log_levels available options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_wf_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export WorldFish Survey Data — export_wf_data","text":"Two data frames (invisible): indicators_df: Aggregated catch metrics submission taxa_df: Species-specific catch information","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_wf_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Export WorldFish Survey Data — export_wf_data","text":"function performs following operations: Retrieves validated WF survey data Pulls submission flags MongoDB Filters submissions alert flags indicators dataset: Aggregates catch data submission Calculates price per kg, CPUE, RPUE metrics taxa dataset: Preserves taxonomic information Calculates catch metrics species metrics calculated include: Total catch weight per submission Price per kg catch CPUE (Catch Per Unit Effort) RPUE (Revenue Per Unit Effort)","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/export_wf_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export WorldFish Survey Data — export_wf_data","text":"","code":"if (FALSE) { # \\dontrun{ # Export WF data with default debug logging export_wf_data()  # Export with info-level logging only export_wf_data(logger::INFO) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/extract_trip_ids_from_filenames.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Trip IDs from Track Filenames — extract_trip_ids_from_filenames","title":"Extract Trip IDs from Track Filenames — extract_trip_ids_from_filenames","text":"Extract Trip IDs Track Filenames","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/extract_trip_ids_from_filenames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Trip IDs from Track Filenames — extract_trip_ids_from_filenames","text":"","code":"extract_trip_ids_from_filenames(filenames)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/extract_trip_ids_from_filenames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Trip IDs from Track Filenames — extract_trip_ids_from_filenames","text":"filenames Character vector track filenames","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/extract_trip_ids_from_filenames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Trip IDs from Track Filenames — extract_trip_ids_from_filenames","text":"Character vector trip IDs","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/extract_trips_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract trip information from preprocessed surveys — extract_trips_info","title":"Extract trip information from preprocessed surveys — extract_trips_info","text":"Extracts relevant trip-level information preprocessed survey data, including location, vessel, fishing effort details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/extract_trips_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract trip information from preprocessed surveys — extract_trips_info","text":"","code":"extract_trips_info(preprocessed_surveys)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/extract_trips_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract trip information from preprocessed surveys — extract_trips_info","text":"preprocessed_surveys preprocessed survey dataframe containing trip information","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/extract_trips_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract trip information from preprocessed surveys — extract_trips_info","text":"dataframe trip-level information","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/flatten_field.html","id":null,"dir":"Reference","previous_headings":"","what":"Flatten Survey Data Fields — flatten_field","title":"Flatten Survey Data Fields — flatten_field","text":"Processes field within row survey data, handling simple vectors nested lists. lists named elements, renames unlists flat structure preparation.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/flatten_field.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flatten Survey Data Fields — flatten_field","text":"","code":"flatten_field(x, p)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/flatten_field.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flatten Survey Data Fields — flatten_field","text":"x vector list representing field data. p prefix name associated field, used naming flattening process.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/flatten_field.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flatten Survey Data Fields — flatten_field","text":"Modified field, either unchanged, unnested, appropriately renamed.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/flatten_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Flatten Survey Data Rows — flatten_row","title":"Flatten Survey Data Rows — flatten_row","text":"Transforms row nested survey data flat tabular format using mapping flattening process.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/flatten_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flatten Survey Data Rows — flatten_row","text":"","code":"flatten_row(x)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/flatten_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flatten Survey Data Rows — flatten_row","text":"x list representing row data, potentially containing nested lists vectors.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/flatten_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flatten Survey Data Rows — flatten_row","text":"tibble row representing flattened survey data.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/getLWCoeffs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","title":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","text":"Retrieves summarizes length-weight relationship coefficients morphological data handling FishBase SeaLifeBase data single workflow.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/getLWCoeffs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","text":"","code":"getLWCoeffs(taxa_list = NULL, asfis_list = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/getLWCoeffs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","text":"taxa_list Character vector FAO 3-alpha codes asfis_list ASFIS list data frame","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/getLWCoeffs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","text":"list two elements: lw - data frame length-weight coefficients: catch_taxon - FAO 3-alpha code n - Number measurements a_6 - 60th percentile parameter '' b_6 - 60th percentile parameter 'b' ml - data frame morphological data: catch_taxon - FAO 3-alpha code n - Number measurements max_length_75 - 75th percentile maximum length max_weightkg_75 - 75th percentile maximum weight kg","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/getLWCoeffs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","text":"","code":"if (FALSE) { # \\dontrun{ # Get coefficients and morphological data results <- getLWCoeffs(taxa_list, asfis_list)  # Access length-weight coefficients lw_coeffs <- results$lw  # Access morphological data morph_data <- results$ml } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_catch_bounds.html","id":null,"dir":"Reference","previous_headings":"","what":"Get catch bounds for survey data — get_catch_bounds","title":"Get catch bounds for survey data — get_catch_bounds","text":"Calculates upper bounds catch weights gear type catch taxon using robust statistical methods. function performs following steps: Filters invalid fish categories Groups data gear fish category Calculates upper bounds log scale exponentiates results","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_catch_bounds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get catch bounds for survey data — get_catch_bounds","text":"","code":"get_catch_bounds(data = NULL, k_param = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_catch_bounds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get catch bounds for survey data — get_catch_bounds","text":"data dataframe containing survey data columns gear, catch_taxon, catch_kg k_param Numeric parameter LocScaleB outlier detection (default: NULL). Higher values conservative outlier detection.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_catch_bounds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get catch bounds for survey data — get_catch_bounds","text":"dataframe containing upper catch bounds gear catch taxon combination","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_fao_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract and Format FAO Taxonomic Groups — get_fao_groups","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"Filters formats taxonomic information FAO ASFIS list specified FAO 3-alpha codes, excluding miscellaneous (\"MZZ\") unknown (\"UNKN\") categories.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_fao_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"","code":"get_fao_groups(fao_codes = NULL, asfis_list = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_fao_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"fao_codes character vector FAO 3-alpha codes extract. NULL, returns empty dataset. asfis_list data frame containing FAO ASFIS list required columns: Alpha3_Code - FAO 3-alpha code Scientific_Name - Scientific name taxon English_name - Common name English Family - Family name Order - Order name ISSCAAP_Group - FAO ISSCAAP group number","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_fao_groups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"tibble standardized column names containing taxonomic information: a3_code - FAO 3-alpha code scientific_name - Scientific name english_name - Common name English family - Family name order - Order name taxon_group - ISSCAAP group number","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_fao_groups.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"function: Filters ASFIS list specified FAO codes Standardizes column names consistency Removes miscellaneous (\"MZZ\") unknown (\"UNKN\") categories Preserves taxonomic hierarchy information","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_fao_groups.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"Requires dplyr package MZZ (Miscellaneous marine fishes) UNKN (Unknown) automatically excluded Column names standardized consistency functions","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_fao_groups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"","code":"# Example ASFIS data asfis <- data.frame(   Alpha3_Code = c(\"TUN\", \"MZZ\", \"RAG\"),   Scientific_Name = c(\"Thunnini\", \"Marine fishes nei\", \"Rastrelliger kanagurta\"),   English_name = c(\"Tunas\", \"Marine fishes\", \"Indian mackerel\"),   Family = c(\"SCOMBRIDAE\", NA, \"SCOMBRIDAE\"),   Order = c(\"PERCIFORMES\", NA, \"PERCIFORMES\"),   ISSCAAP_Group = c(36, 39, 37) )  # Get taxonomic information for specific codes fao_taxa <- get_fao_groups(c(\"TUN\", \"RAG\"), asfis)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_length_bounds.html","id":null,"dir":"Reference","previous_headings":"","what":"Get length bounds for survey data — get_length_bounds","title":"Get length bounds for survey data — get_length_bounds","text":"Calculates upper bounds fish lengths gear type catch taxon using robust statistical methods. Similar get_catch_bounds length measurements. function: Filters invalid fish categories Groups data gear fish category Calculates upper bounds log scale exponentiates results","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_length_bounds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get length bounds for survey data — get_length_bounds","text":"","code":"get_length_bounds(data = NULL, k_param = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_length_bounds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get length bounds for survey data — get_length_bounds","text":"data dataframe containing survey data columns gear, catch_taxon, length_cm k_param Numeric parameter LocScaleB outlier detection (default: NULL). Higher values conservative outlier detection.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_length_bounds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get length bounds for survey data — get_length_bounds","text":"dataframe containing upper length bounds gear catch taxon combination","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_length_weight_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"Retrieves length-weight relationship parameters optional morphological data multiple species efficiently processing batches. Handles fish non-fish species appropriately.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_length_weight_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"","code":"get_length_weight_batch(species_areas_filtered, include_morphology = FALSE)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_length_weight_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"species_areas_filtered Data frame filtered species include_morphology Logical, whether include morphological data (Length, CommonLength, Weight). Default FALSE.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_length_weight_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"include_morphology FALSE (default), data frame columns: a3_code: FAO 3-alpha code species: Scientific name area_code: FAO area code database: Source database type: Measurement type (e.g., \"TL\" total length) : Length-weight parameter b: Length-weight parameter b include_morphology TRUE, list two elements: length_weight: Data frame described morphology: Data frame columns: a3_code: FAO 3-alpha code species: Scientific name area_code: FAO area code database: Source database Length: Maximum recorded length CommonLength: Common length Weight: Maximum weight","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_length_weight_batch.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"FishBase species, total length (TL) measurements used Questionable estimates (EsQ = \"yes\") excluded","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_length_weight_batch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"","code":"if (FALSE) { # \\dontrun{ # Get just length-weight parameters lw_data <- get_length_weight_batch(species_areas_filtered)  # Get both length-weight and morphological data results <- get_length_weight_batch(species_areas_filtered, include_morphology = TRUE) lw_data <- results$length_weight morph_data <- results$morphology } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Get metadata tables — get_metadata","title":"Get metadata tables — get_metadata","text":"Get Metadata tables Google sheets. function downloads tables include information fishery. can specify single table download get available tables.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get metadata tables — get_metadata","text":"","code":"get_metadata(table = NULL, log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get metadata tables — get_metadata","text":"table Character. Name specific table download. NULL (default), tables specified configuration downloaded. log_threshold logging threshold level. Default logger::DEBUG.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get metadata tables — get_metadata","text":"named list containing requested tables data frames. single table requested, list contain table. table specified, list contain available tables.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_metadata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get metadata tables — get_metadata","text":"parameters needed conf.yml :","code":"storage:   storage_name:     key:     options:       project:       bucket:       service_account_key: metadata:   google_sheets:     sheet_id:     tables:       - table1       - table2"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get metadata tables — get_metadata","text":"","code":"if (FALSE) { # \\dontrun{ # Ensure you have the necessary configuration in conf.yml  # Download all metadata tables metadata_tables <- get_metadata()  # Download a specific table catch_table <- get_metadata(table = \"devices\") } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_preprocessed_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Preprocessed Surveys — get_preprocessed_surveys","title":"Download Preprocessed Surveys — get_preprocessed_surveys","text":"Retrieves preprocessed survey data Google Cloud Storage, specifically configured WCS (Wildlife Conservation Society) datasets. function fetches data stored Parquet format.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_preprocessed_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Preprocessed Surveys — get_preprocessed_surveys","text":"","code":"get_preprocessed_surveys(pars, prefix = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_preprocessed_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Preprocessed Surveys — get_preprocessed_surveys","text":"pars list representing configuration settings, typically obtained YAML configuration file. prefix character string specifying organization prefix retrieve preprocessed surveys, either \"wcs\" \"ba\".","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_preprocessed_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Preprocessed Surveys — get_preprocessed_surveys","text":"dataframe preprocessed survey landings, loaded Parquet files.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_preprocessed_surveys.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Preprocessed Surveys — get_preprocessed_surveys","text":"","code":"if (FALSE) { # \\dontrun{ config <- peskas.zanzibar.pipeline::read_config() df_preprocessed <- get_preprocessed_surveys(config, prefix = \"ba\") } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_species_areas_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","title":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","text":"Efficiently retrieves FAO areas multiple species processing batches database source, reducing API calls processing time.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_species_areas_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","text":"","code":"get_species_areas_batch(matched_species)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_species_areas_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","text":"matched_species Data frame match_species_from_taxa()","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_species_areas_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","text":"data frame columns: a3_code: FAO 3-alpha code species: Scientific name area_code: FAO area code database: Source database","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_species_areas_batch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","text":"","code":"if (FALSE) { # \\dontrun{ species_areas <- get_species_areas_batch(matched_species) # Filter for specific FAO area area_51_species <- species_areas %>%   dplyr::filter(area_code == 51) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_trip_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Trip Points from Pelagic Data Systems API — get_trip_points","title":"Get Trip Points from Pelagic Data Systems API — get_trip_points","text":"Retrieves trip points data Pelagic Data Systems API. function can either fetch data specific trip ID date range. response can returned data frame written directly file.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_trip_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Trip Points from Pelagic Data Systems API — get_trip_points","text":"","code":"get_trip_points(   token = NULL,   secret = NULL,   id = NULL,   dateFrom = NULL,   dateTo = NULL,   path = NULL,   imeis = NULL,   deviceInfo = FALSE,   errant = FALSE,   withLastSeen = FALSE,   tags = NULL,   overwrite = TRUE )"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_trip_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Trip Points from Pelagic Data Systems API — get_trip_points","text":"token Character string. Access token PDS API. secret Character string. Secret key PDS API. id Numeric character. Optional trip ID. provided, retrieves points specific trip. NULL, dateFrom dateTo must provided. dateFrom Character string. Start date data retrieval format \"YYYY-MM-DD\". Required id NULL. dateTo Character string. End date data retrieval format \"YYYY-MM-DD\". Required id NULL. path Character string. Optional path CSV file saved. provided, function returns path instead data frame. imeis Vector character numeric. Optional IMEI numbers filter data. deviceInfo Logical. TRUE, includes device information response. Default FALSE. errant Logical. TRUE, includes errant points response. Default FALSE. withLastSeen Logical. TRUE, includes last seen information. Default FALSE. tags Vector character. Optional tags filter data. overwrite Logical. TRUE, overwrite existing file path provided. Default TRUE.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_trip_points.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Trip Points from Pelagic Data Systems API — get_trip_points","text":"path NULL, returns tibble containing trip points data. path provided, returns file path character string.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_trip_points.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Trip Points from Pelagic Data Systems API — get_trip_points","text":"","code":"if (FALSE) { # \\dontrun{ # Get data for a specific trip trip_data <- get_trip_points(   token = \"your_token\",   secret = \"your_secret\",   id = \"12345\",   deviceInfo = TRUE )  # Get data for a date range date_data <- get_trip_points(   token = \"your_token\",   secret = \"your_secret\",   dateFrom = \"2024-01-01\",   dateTo = \"2024-01-31\" )  # Save data directly to file file_path <- get_trip_points(   token = \"your_token\",   secret = \"your_secret\",   id = \"12345\",   path = \"trip_data.csv\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_trips.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Trip Details from Pelagic Data API — get_trips","title":"Retrieve Trip Details from Pelagic Data API — get_trips","text":"function retrieves trip details Pelagic Data API specified time range, options filter IMEIs include additional information.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_trips.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Trip Details from Pelagic Data API — get_trips","text":"","code":"get_trips(   token = NULL,   secret = NULL,   dateFrom = NULL,   dateTo = NULL,   imeis = NULL,   deviceInfo = FALSE,   withLastSeen = FALSE,   tags = NULL )"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_trips.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Trip Details from Pelagic Data API — get_trips","text":"token Character string. API token authentication. secret Character string. API secret authentication. dateFrom Character string. Start date 'YYYY-MM-dd' format. dateTo Character string. End date 'YYYY-MM-dd' format. imeis Character vector. Optional. Filter IMEI numbers. deviceInfo Logical. TRUE, include device IMEI ID fields response. Default FALSE. withLastSeen Logical. TRUE, include device last seen date response. Default FALSE. tags Character vector. Optional. Filter trip tags.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_trips.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Trip Details from Pelagic Data API — get_trips","text":"data frame containing trip details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_trips.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Trip Details from Pelagic Data API — get_trips","text":"","code":"if (FALSE) { # \\dontrun{ trips <- get_trips(   token = \"your_token\",   secret = \"your_secret\",   dateFrom = \"2020-05-01\",   dateTo = \"2020-05-03\",   imeis = c(\"123456789\", \"987654321\"),   deviceInfo = TRUE,   withLastSeen = TRUE,   tags = c(\"tag1\", \"tag2\") ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_validated_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Validated Surveys — get_validated_surveys","title":"Download Validated Surveys — get_validated_surveys","text":"Retrieves validated survey data Google Cloud Storage multiple survey sources. function fetches data stored Parquet format sources defined configuration.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_validated_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Validated Surveys — get_validated_surveys","text":"","code":"get_validated_surveys(pars, sources = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_validated_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Validated Surveys — get_validated_surveys","text":"pars list representing configuration settings, typically obtained YAML configuration file. sources Character vector specifying survey sources retrieve (e.g., \"wcs\", \"wf\", \"ba\"). NULL (default), retrieves data available sources.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_validated_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Validated Surveys — get_validated_surveys","text":"dataframe validated survey landings requested sources, loaded Parquet files.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_validated_surveys.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Validated Surveys — get_validated_surveys","text":"","code":"if (FALSE) { # \\dontrun{ config <- peskas.zanzibar.pipeline::read_config() # Get all available validated surveys all_validated <- get_validated_surveys(config)  # Get only WCS and BA validated surveys some_validated <- get_validated_surveys(config, sources = c(\"wcs\", \"ba\")) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_validation_status.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Validation Status from KoboToolbox — get_validation_status","title":"Get Validation Status from KoboToolbox — get_validation_status","text":"Retrieves validation status specific submission KoboToolbox. function handles NULL responses returns consistent tibble structure regardless API response.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_validation_status.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Validation Status from KoboToolbox — get_validation_status","text":"","code":"get_validation_status(   submission_id = NULL,   asset_id = NULL,   token = NULL,   debug = FALSE )"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_validation_status.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Validation Status from KoboToolbox — get_validation_status","text":"submission_id Character string. ID submission check. asset_id Character string. asset ID KoboToolbox. token Character string. authorization token KoboToolbox API. debug Logical. TRUE, prints request object. Default FALSE.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_validation_status.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Validation Status from KoboToolbox — get_validation_status","text":"tibble one row containing: submission_id ID checked submission validation_status validation status (e.g., \"validation_status_approved\" \"not_validated\") validated_at Timestamp validation POSIXct validated_by Username validator","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/get_validation_status.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Validation Status from KoboToolbox — get_validation_status","text":"","code":"if (FALSE) { # \\dontrun{ # Single submission get_validation_status(   submission_id = \"1234567\",   asset_id = \"your asset id\",   token = \"Token YOUR_TOKEN_HERE\" )  # Multiple submissions using purrr submission_ids <- c(\"1234567\", \"154267\") submission_ids %>%   purrr::map_dfr(get_validation_status,     asset_id = \"your asset id\",     token = \"Token YOUR_TOKEN_HERE\"   ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_pds_tracks.html","id":null,"dir":"Reference","previous_headings":"","what":"Ingest Pelagic Data Systems (PDS) Track Data — ingest_pds_tracks","title":"Ingest Pelagic Data Systems (PDS) Track Data — ingest_pds_tracks","text":"function handles automated ingestion GPS boat track data Pelagic Data Systems (PDS). downloads stores new tracks previously uploaded Google Cloud Storage. Uses parallel processing improved performance.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_pds_tracks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ingest Pelagic Data Systems (PDS) Track Data — ingest_pds_tracks","text":"","code":"ingest_pds_tracks(log_threshold = logger::DEBUG, batch_size = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_pds_tracks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ingest Pelagic Data Systems (PDS) Track Data — ingest_pds_tracks","text":"log_threshold logging threshold use. Default logger::DEBUG. batch_size Optional number tracks process. NULL, processes new tracks.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_pds_tracks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ingest Pelagic Data Systems (PDS) Track Data — ingest_pds_tracks","text":"None (invisible). function performs operations side effects.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_pds_trips.html","id":null,"dir":"Reference","previous_headings":"","what":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"function handles automated ingestion GPS boat trip data Pelagic Data Systems (PDS). performs following operations: Retrieves device metadata configured source Downloads trip data PDS API using device IMEIs Converts data parquet format Uploads processed file configured cloud storage","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_pds_trips.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"","code":"ingest_pds_trips(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_pds_trips.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"log_threshold logging threshold use. Default logger::DEBUG. See logger::log_levels available options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_pds_trips.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"None (invisible). function performs operations side effects: Creates parquet file locally trip data Uploads file configured cloud storage Generates logs process","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_pds_trips.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"function requires specific configuration conf.yml file following structure:   function processes trips sequentially: Retrieves device metadata using get_metadata() Downloads trip data using get_trips() function Converts data parquet format Uploads resulting file configured storage provider","code":"pds:   token: \"your_pds_token\"               # PDS API token   secret: \"your_pds_secret\"             # PDS API secret   pds_trips:     file_prefix: \"pds_trips\"            # Prefix for output files storage:   google:                               # Storage provider name     key: \"google\"                       # Storage provider identifier     options:       project: \"project-id\"             # Cloud project ID       bucket: \"bucket-name\"             # Storage bucket name       service_account_key: \"path/to/key.json\""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_pds_trips.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"","code":"if (FALSE) { # \\dontrun{ # Run with default debug logging ingest_pds_trips()  # Run with info-level logging only ingest_pds_trips(logger::INFO) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Ingest WCS and WF Catch Survey Data — ingest_surveys","title":"Ingest WCS and WF Catch Survey Data — ingest_surveys","text":"function handles automated ingestion fish catch survey data WCS WF sources Kobo Toolbox. performs following operations: Downloads survey data Kobo Toolbox Processes formats data Uploads processed files configured cloud storage locations","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ingest WCS and WF Catch Survey Data — ingest_surveys","text":"","code":"ingest_surveys(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ingest WCS and WF Catch Survey Data — ingest_surveys","text":"log_threshold logging threshold use. Default logger::DEBUG. See logger::log_levels available options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ingest WCS and WF Catch Survey Data — ingest_surveys","text":"None (invisible). function performs operations side effects: Creates parquet files locally Uploads files configured cloud storage Generates logs process","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_surveys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ingest WCS and WF Catch Survey Data — ingest_surveys","text":"function requires specific configuration conf.yml file following structure:   function processes WCS WF surveys sequentially, separate logging step. survey: Downloads data using retrieve_surveys() function Converts data parquet format Uploads resulting files configured storage providers Error handling managed logger package, informative messages step process.","code":"surveys:   wcs_surveys:     raw_surveys:       file_prefix: \"wcs_raw_data\"     # Prefix for output files       asset_id: \"xxxxx\"               # Kobo Toolbox asset ID       username: \"user@example.com\"    # Kobo Toolbox username       password: \"password123\"         # Kobo Toolbox password   wf_surveys:     raw_surveys:       file_prefix: \"wf_raw_data\"       asset_id: \"yyyyy\"       username: \"user2@example.com\"       password: \"password456\" storage:   gcp:                               # Storage provider name     key: \"google\"                    # Storage provider identifier     options:       project: \"project-id\"          # Cloud project ID       bucket: \"bucket-name\"          # Storage bucket name       service_account_key: \"path/to/key.json\""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/ingest_surveys.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ingest WCS and WF Catch Survey Data — ingest_surveys","text":"","code":"if (FALSE) { # \\dontrun{ # Run with default debug logging ingest_surveys()  # Run with info-level logging only ingest_surveys(logger::INFO) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/kepler_mapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a Kepler.gl map — kepler_mapper","title":"Generate a Kepler.gl map — kepler_mapper","text":"function R wrapper kepler_wcs_mapper_py, python script function aimed elaborate produce self-contained map (html) using Kepler.gl python library https://docs.kepler.gl/docs/keplergl-jupyter.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/kepler_mapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a Kepler.gl map — kepler_mapper","text":"","code":"kepler_mapper(data_path = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/kepler_mapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a Kepler.gl map — kepler_mapper","text":"data_path Data add map.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/kepler_mapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a Kepler.gl map — kepler_mapper","text":"self-contained map html.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/load_taxa_databases.html","id":null,"dir":"Reference","previous_headings":"","what":"Load Taxa Data from FishBase and SeaLifeBase — load_taxa_databases","title":"Load Taxa Data from FishBase and SeaLifeBase — load_taxa_databases","text":"Retrieves taxonomic data FishBase SeaLifeBase databases single function call. typically first step species identification classification.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/load_taxa_databases.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load Taxa Data from FishBase and SeaLifeBase — load_taxa_databases","text":"","code":"load_taxa_databases()"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/load_taxa_databases.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load Taxa Data from FishBase and SeaLifeBase — load_taxa_databases","text":"list two elements: fishbase: Data frame containing FishBase taxonomic data sealifebase: Data frame containing SeaLifeBase taxonomic data","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/load_taxa_databases.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load Taxa Data from FishBase and SeaLifeBase — load_taxa_databases","text":"","code":"if (FALSE) { # \\dontrun{ taxa_data <- load_taxa_databases() fishbase_taxa <- taxa_data$fishbase sealifebase_taxa <- taxa_data$sealifebase } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/match_species_from_taxa.html","id":null,"dir":"Reference","previous_headings":"","what":"Match Species from Taxa Databases — match_species_from_taxa","title":"Match Species from Taxa Databases — match_species_from_taxa","text":"Matches species FAO codes database records, handling different taxonomic levels (species, genus, family, order) appropriately.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/match_species_from_taxa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match Species from Taxa Databases — match_species_from_taxa","text":"","code":"match_species_from_taxa(species_list, taxa_data)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/match_species_from_taxa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match Species from Taxa Databases — match_species_from_taxa","text":"species_list Processed species list process_species_list() taxa_data Taxa data load_taxa_databases()","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/match_species_from_taxa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Match Species from Taxa Databases — match_species_from_taxa","text":"data frame columns: a3_code: FAO 3-alpha code species: Scientific name database: Source database","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/match_species_from_taxa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Match Species from Taxa Databases — match_species_from_taxa","text":"","code":"if (FALSE) { # \\dontrun{ taxa_data <- load_taxa_databases() species_list <- process_species_list(fao_codes, asfis) matches <- match_species_from_taxa(species_list, taxa_data) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/mdb_collection_pull.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Data from MongoDB — mdb_collection_pull","title":"Retrieve Data from MongoDB — mdb_collection_pull","text":"function connects MongoDB database retrieves documents specified collection, maintaining original column order available.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/mdb_collection_pull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Data from MongoDB — mdb_collection_pull","text":"","code":"mdb_collection_pull(   connection_string = NULL,   collection_name = NULL,   db_name = NULL )"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/mdb_collection_pull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Data from MongoDB — mdb_collection_pull","text":"connection_string character string specifying MongoDB connection URL. Default NULL. collection_name character string specifying name collection query. Default NULL. db_name character string specifying name database. Default NULL.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/mdb_collection_pull.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Data from MongoDB — mdb_collection_pull","text":"data frame containing documents specified collection, columns ordered data originally pushed MongoDB.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/mdb_collection_pull.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Data from MongoDB — mdb_collection_pull","text":"","code":"if (FALSE) { # \\dontrun{ # Retrieve data from a MongoDB collection result <- mdb_collection_pull(   connection_string = \"mongodb://localhost:27017\",   collection_name = \"my_collection\",   db_name = \"my_database\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/mdb_collection_push.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","title":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","text":"function connects MongoDB database, removes existing documents specified collection, inserts new data. also stores original column order maintain data structure consistency.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/mdb_collection_push.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","text":"","code":"mdb_collection_push(   data = NULL,   connection_string = NULL,   collection_name = NULL,   db_name = NULL )"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/mdb_collection_push.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","text":"data data frame containing data uploaded. connection_string character string specifying MongoDB connection URL. collection_name character string specifying name collection. db_name character string specifying name database.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/mdb_collection_push.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","text":"number data documents inserted collection (excluding order document).","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/mdb_collection_push.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","text":"","code":"if (FALSE) { # \\dontrun{ # Upload and overwrite data in a MongoDB collection result <- mdb_collection_push(   data = processed_legacy_landings,   connection_string = \"mongodb://localhost:27017\",   collection_name = \"my_collection\",   db_name = \"my_database\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_ba_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Pre-process Blue Alliance Surveys — preprocess_ba_surveys","title":"Pre-process Blue Alliance Surveys — preprocess_ba_surveys","text":"Downloads preprocesses raw structured Blue Alliance survey data cloud storage binary format. process includes date standardization survey ID generation unique trip identification.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_ba_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pre-process Blue Alliance Surveys — preprocess_ba_surveys","text":"","code":"preprocess_ba_surveys(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_ba_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pre-process Blue Alliance Surveys — preprocess_ba_surveys","text":"log_threshold logging threshold use. Default logger::DEBUG. See logger::log_levels available options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_ba_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pre-process Blue Alliance Surveys — preprocess_ba_surveys","text":"None; function used side effects.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_ba_surveys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pre-process Blue Alliance Surveys — preprocess_ba_surveys","text":"Configurations read conf.yml following necessary parameters:   function uses logging track progress creates unique survey IDs using CRC32 hashing concatenated trip attributes.","code":"surveys:   ba_surveys:     asset_id:     username:     password:     file_prefix:   version:     preprocess: storage:   storage_name:     key:     options:       project:       bucket:       service_account_key:"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_pds_tracks.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Pelagic Data Systems (PDS) Track Data — preprocess_pds_tracks","title":"Preprocess Pelagic Data Systems (PDS) Track Data — preprocess_pds_tracks","text":"Downloads raw GPS tracks creates gridded summary fishing activity.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_pds_tracks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Pelagic Data Systems (PDS) Track Data — preprocess_pds_tracks","text":"","code":"preprocess_pds_tracks(log_threshold = logger::DEBUG, grid_size = 500)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_pds_tracks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Pelagic Data Systems (PDS) Track Data — preprocess_pds_tracks","text":"log_threshold logging threshold use. Default logger::DEBUG. grid_size Numeric. Size grid cells meters (100, 250, 500, 1000).","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_pds_tracks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Pelagic Data Systems (PDS) Track Data — preprocess_pds_tracks","text":"None (invisible). Creates uploads preprocessed files.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_track_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"function processes GPS track data spatial grid summary, calculating time spent metrics grid cell. grid size can specified analyze spatial patterns different scales.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_track_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"","code":"preprocess_track_data(data, grid_size = 500)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_track_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"data data frame containing GPS track data columns: Trip: Unique trip identifier Time: Timestamp GPS point Lat: Latitude Lng: Longitude Speed (M/S): Speed meters per second Range (Meters): Range meters Heading: Heading degrees grid_size Numeric. Size grid cells meters. Must one : 100: ~100m grid cells 250: ~250m grid cells 500: ~500m grid cells (default) 1000: ~1km grid cells","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_track_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"tibble following columns: Trip: Trip identifier lat_grid: Latitude grid cell center lng_grid: Longitude grid cell center time_spent_mins: Total time spent grid cell minutes mean_speed: Average speed grid cell (M/S) mean_range: Average range grid cell (Meters) first_seen: First timestamp grid cell last_seen: Last timestamp grid cell n_points: Number GPS points grid cell","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_track_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"function creates grid rounding coordinates based specified grid size. Grid sizes approximate due conversion meters degrees, calculations based 1 degree ≈ 111km equator. Time spent calculated using time differences consecutive points.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_track_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"","code":"if (FALSE) { # \\dontrun{ # Process tracks with 500m grid (default) result_500m <- preprocess_track_data(tracks_data)  # Use 100m grid for finer resolution result_100m <- preprocess_track_data(tracks_data, grid_size = 100)  # Use 1km grid for broader patterns result_1km <- preprocess_track_data(tracks_data, grid_size = 1000) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_wcs_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Pre-process Zanzibar WCS Surveys — preprocess_wcs_surveys","title":"Pre-process Zanzibar WCS Surveys — preprocess_wcs_surveys","text":"Downloads preprocesses raw structured WCS survey data cloud storage binary format. process includes nesting multiple columns related species information single columns within dataframe, helps reduce width organize data efficiently analysis.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_wcs_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pre-process Zanzibar WCS Surveys — preprocess_wcs_surveys","text":"","code":"preprocess_wcs_surveys(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_wcs_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pre-process Zanzibar WCS Surveys — preprocess_wcs_surveys","text":"log_threshold logging threshold use. Default logger::DEBUG. See logger::log_levels available options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_wcs_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pre-process Zanzibar WCS Surveys — preprocess_wcs_surveys","text":"None; function used side effects.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_wcs_surveys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pre-process Zanzibar WCS Surveys — preprocess_wcs_surveys","text":"Configurations read conf.yml following necessary parameters:   function uses logging track progress.","code":"surveys:   wcs_surveys:     asset_id:     username:     password:     file_prefix:   version:     preprocess: storage:   storage_name:     key:     options:       project:       bucket:       service_account_key:"},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_wf_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Pre-process WorldFish Surveys — preprocess_wf_surveys","title":"Pre-process WorldFish Surveys — preprocess_wf_surveys","text":"Downloads preprocesses raw structured WorldFish survey data cloud storage binary format. process includes organizing data general trip information structured format optimized analysis.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_wf_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pre-process WorldFish Surveys — preprocess_wf_surveys","text":"","code":"preprocess_wf_surveys(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_wf_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pre-process WorldFish Surveys — preprocess_wf_surveys","text":"log_threshold logging threshold use. Default logger::DEBUG. See logger::log_levels available options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_wf_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pre-process WorldFish Surveys — preprocess_wf_surveys","text":"None; function used side effects.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/preprocess_wf_surveys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pre-process WorldFish Surveys — preprocess_wf_surveys","text":"Configurations read conf.yml following necessary parameters:   function uses logging track progress.","code":"surveys:   wf_surveys:     asset_id:     username:     password:     file_prefix:   version:     preprocess: storage:   storage_name:     key:     options:       project:       bucket:       service_account_key:"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_catch_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Process catch data from surveys — process_catch_data","title":"Process catch data from surveys — process_catch_data","text":"Processes structures catch data surveys, including catch numbers associated vessel/gear information.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_catch_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process catch data from surveys — process_catch_data","text":"","code":"process_catch_data(preprocessed_surveys, trips_info)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_catch_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process catch data from surveys — process_catch_data","text":"preprocessed_surveys preprocessed survey dataframe trips_info Trip information dataframe extract_trips_info","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_catch_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process catch data from surveys — process_catch_data","text":"dataframe containing processed catch data","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_single_track.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Single PDS Track — process_single_track","title":"Process Single PDS Track — process_single_track","text":"Process Single PDS Track","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_single_track.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Single PDS Track — process_single_track","text":"","code":"process_single_track(trip_id, pars)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_single_track.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Single PDS Track — process_single_track","text":"trip_id Character. ID trip process. pars List. Configuration parameters.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_single_track.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Single PDS Track — process_single_track","text":"List processing status details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_species_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Species List with Taxonomic Information — process_species_list","title":"Process Species List with Taxonomic Information — process_species_list","text":"Processes list species assigning database sources taxonomic ranks. Determines whether species looked FishBase SeaLifeBase based ISSCAAP group.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_species_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Species List with Taxonomic Information — process_species_list","text":"","code":"process_species_list(fao_codes, asfis_list)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_species_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Species List with Taxonomic Information — process_species_list","text":"fao_codes Vector FAO 3-alpha codes asfis_list ASFIS list data frame containing taxonomic information","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_species_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Species List with Taxonomic Information — process_species_list","text":"data frame columns: a3_code: FAO 3-alpha code scientific_name: Scientific name (cleaned) database: \"fishbase\" \"sealifebase\" rank: Taxonomic rank (\"Genus\", \"Family\", \"Order\", \"Species\") ... (taxonomic fields)","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_species_list.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process Species List with Taxonomic Information — process_species_list","text":"ISSCAAP groups 57, 45, 43, 42, 56 assigned SeaLifeBase; others FishBase","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/process_species_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Species List with Taxonomic Information — process_species_list","text":"","code":"if (FALSE) { # \\dontrun{ species_list <- process_species_list(c(\"TUN\", \"PEZ\"), asfis_data) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_attachments.html","id":null,"dir":"Reference","previous_headings":"","what":"Nest Attachment Columns — pt_nest_attachments","title":"Nest Attachment Columns — pt_nest_attachments","text":"Nests attachment-related columns structured WCS survey data, organizing multiple attachment entries single nested column. function addresses challenge handling wide data tables converting manageable nested data frames.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_attachments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nest Attachment Columns — pt_nest_attachments","text":"","code":"pt_nest_attachments(x)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_attachments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nest Attachment Columns — pt_nest_attachments","text":"x data frame containing raw survey data, potentially multiple attachments per survey entry.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_attachments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nest Attachment Columns — pt_nest_attachments","text":"data frame attachment information nested single '_attachments' column, containing tibble row.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_attachments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nest Attachment Columns — pt_nest_attachments","text":"","code":"if (FALSE) { # \\dontrun{ dummy_landings <- tidyr::tibble(   `_id` = \"123\",   `_attachments.0.download_url` = \"http://url-1.com\",   `_attachments.0.id` = \"01\",   `_attachments.1.download_url` = \"http://url-2.com\",   `_attachments.1.id` = \"02\",   `_attachments.2.download_url` = NA,   `_attachments.2.id` = NA ) pt_nest_attachments(dummy_landings) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Nest Catch Group Columns — pt_nest_catch","title":"Nest Catch Group Columns — pt_nest_catch","text":"Nests catch group columns WCS structured survey data organize multiple related catch data points single nested 'catch' column per row.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nest Catch Group Columns — pt_nest_catch","text":"","code":"pt_nest_catch(x)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_catch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nest Catch Group Columns — pt_nest_catch","text":"x Data frame WCS survey data tabular format.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_catch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nest Catch Group Columns — pt_nest_catch","text":"data frame catch data nested 'catch' column, containing tibble row various catch-related attributes.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_length.html","id":null,"dir":"Reference","previous_headings":"","what":"Nest Length Group Columns — pt_nest_length","title":"Nest Length Group Columns — pt_nest_length","text":"Nests length group columns obtained structured data WCS landings surveys. reduces width data converting multiple related columns single nested column.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_length.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nest Length Group Columns — pt_nest_length","text":"","code":"pt_nest_length(x)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_length.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nest Length Group Columns — pt_nest_length","text":"x Data frame WCS survey data tabular format.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_length.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nest Length Group Columns — pt_nest_length","text":"data frame length data nested single 'length' column, contains tibble row multiple measurements.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_market.html","id":null,"dir":"Reference","previous_headings":"","what":"Nest Market Group Columns — pt_nest_market","title":"Nest Market Group Columns — pt_nest_market","text":"Nests market group columns structured WCS landings survey data. method organizes multiple related market data points single nested 'market' column per row.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_market.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nest Market Group Columns — pt_nest_market","text":"","code":"pt_nest_market(x)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_market.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nest Market Group Columns — pt_nest_market","text":"x Data frame WCS survey data tabular format.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_market.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nest Market Group Columns — pt_nest_market","text":"data frame market data nested 'market' column, containing tibble row various market-related attributes.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_trip.html","id":null,"dir":"Reference","previous_headings":"","what":"Nest Trip Group Columns — pt_nest_trip","title":"Nest Trip Group Columns — pt_nest_trip","text":"Processes nests trip-related columns structured WCS landings survey data single 'trip' column. approach consolidates trip information nested tibbles within dataframe, simplifying structure analysis.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_trip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nest Trip Group Columns — pt_nest_trip","text":"","code":"pt_nest_trip(x)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_trip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nest Trip Group Columns — pt_nest_trip","text":"x data frame containing structured survey data tabular format.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/pt_nest_trip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nest Trip Group Columns — pt_nest_trip","text":"data frame trip data nested single 'trip' column containing tibble row, corresponding various trip details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/read_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Read configuration file — read_config","title":"Read configuration file — read_config","text":"Reads configuration file conf.yml adds logging lines. Wrapped convenience","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/read_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read configuration file — read_config","text":"","code":"read_config()"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/read_config.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read configuration file — read_config","text":"environment parameters","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/rename_child.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename Nested Survey Data Elements — rename_child","title":"Rename Nested Survey Data Elements — rename_child","text":"Appends parent name index child elements within nested list, assisting creating coherent traceable data structure flattening process.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/rename_child.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename Nested Survey Data Elements — rename_child","text":"","code":"rename_child(x, i, p)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/rename_child.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename Nested Survey Data Elements — rename_child","text":"x list element, possibly nested, renamed. index key element within parent list. p parent name prepend element's existing name context.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/rename_child.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rename Nested Survey Data Elements — rename_child","text":"renamed list element, structured maintain contextual relevance flattened dataset.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_catch_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape Catch Data with Length Groupings — reshape_catch_data","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"function takes data frame species catch information reshapes long format properly handling nested length group information.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_catch_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"","code":"reshape_catch_data(df = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_catch_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"df data frame containing catch data species groups length information","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_catch_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"data frame long format row representing species specific length range, just species data length information available","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_catch_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"function first calls reshape_species_groups() convert species data long format, handles length group information. length data, creates separate rows length category preserving original structure catches without length measurements. Special handling provided fish 100cm, actual length moved separate column. function preserves rows, even without length data, creating consistent column structure across rows.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_catch_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"","code":"if (FALSE) { # \\dontrun{ final_data <- reshape_catch_data(catch_info)  # Analyze counts by length range final_data |>   filter(!is.na(count)) |>   group_by(species, length_range) |>   summarize(total_count = sum(as.numeric(count), na.rm = TRUE)) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_species_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"function converts data frame containing repeated species group columns (species_group.0, species_group.1, etc.) long format species group represented separate row, column indicating group belongs .","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_species_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"","code":"reshape_species_groups(df = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_species_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"df data frame containing species group data wide format","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_species_groups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"data frame long format row representing single species group record","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_species_groups.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"function identifies columns follow pattern \"species_group.X\" restructures data species group submission represented separate row. removes position prefix column names adds n_catch column track group number (1-based indexing). Rows contain NA values filtered .","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/reshape_species_groups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"","code":"if (FALSE) { # \\dontrun{ long_species_data <- reshape_species_groups(catch_info) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/retrieve_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Surveys from Kobotoolbox — retrieve_surveys","title":"Retrieve Surveys from Kobotoolbox — retrieve_surveys","text":"Downloads survey data Kobotoolbox specified project uploads data Parquet format. File naming can include versioning details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/retrieve_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Surveys from Kobotoolbox — retrieve_surveys","text":"","code":"retrieve_surveys(   prefix = NULL,   append_version = NULL,   url = NULL,   project_id = NULL,   username = NULL,   psswd = NULL,   encoding = NULL )"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/retrieve_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Surveys from Kobotoolbox — retrieve_surveys","text":"prefix Filename prefix path downloaded files. append_version Boolean indicating whether append versioning info filenames. url URL Kobotoolbox instance. project_id Project asset ID data download. username Kobotoolbox account username. psswd Kobotoolbox account password. encoding Character encoding downloaded data; defaults \"UTF-8\".","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/retrieve_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Surveys from Kobotoolbox — retrieve_surveys","text":"Vector paths downloaded Parquet files.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/retrieve_surveys.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Surveys from Kobotoolbox — retrieve_surveys","text":"","code":"if (FALSE) { # \\dontrun{ file_list <- retrieve_surveys(   prefix = \"my_data\",   append_version = TRUE,   url = \"kf.kobotoolbox.org\",   project_id = \"my_project_id\",   username = \"admin\",   psswd = \"admin\",   encoding = \"UTF-8\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"sym() creates symbol string syms() creates list symbols character vector. enquo() enquos() delay execution one several function arguments. enquo() returns single quoted expression, like blueprint delayed computation. enquos() returns list quoted expressions. expr() quotes new expression locally. mostly useful build new expressions around arguments captured enquo() enquos(): expr(mean(!!enquo(arg), na.rm = TRUE)). as_name() transforms quoted variable name string. Supplying something else quoted variable name error. unlike as_label() also returns single string supports kind R object input, including quoted function calls vectors. purpose summarise object single label. label often suitable default name. know quoted expression contains (instance expressions captured enquo() variable name, call function, unquoted constant), use as_label(). know quoted simple variable name, like enforce , use as_name(). learn tidy eval use tools, visit https://tidyeval.tidyverse.org Metaprogramming section Advanced R.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_cloud_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload File to Cloud Storage — upload_cloud_file","title":"Upload File to Cloud Storage — upload_cloud_file","text":"Uploads local file specified cloud storage bucket, supporting single multiple files.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_cloud_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload File to Cloud Storage — upload_cloud_file","text":"","code":"upload_cloud_file(file, provider, options, name = file)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_cloud_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload File to Cloud Storage — upload_cloud_file","text":"file character vector specifying path(s) file(s) upload. provider character string specifying cloud provider (\"gcs\" \"aws\"). options named list provider-specific options including bucket authentication details. name (Optional) name assign file cloud. specified, local file name used.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_cloud_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upload File to Cloud Storage — upload_cloud_file","text":"list metadata objects uploaded files successful.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_cloud_file.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Upload File to Cloud Storage — upload_cloud_file","text":"GCS, options list must include: bucket: name bucket files uploaded. service_account_key: authentication JSON contents, previously authenticated. function utilizes googleCloudStorageR::gcs_upload() file uploads GCS.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_cloud_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upload File to Cloud Storage — upload_cloud_file","text":"","code":"if (FALSE) { # \\dontrun{ authentication_details <- readLines(\"path/to/json_file.json\") upload_cloud_file(   \"path/to/local_file.csv\",   \"gcs\",   list(service_account_key = authentication_details, bucket = \"my-bucket\") ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_parquet_to_cloud.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload Processed Data to Cloud Storage — upload_parquet_to_cloud","title":"Upload Processed Data to Cloud Storage — upload_parquet_to_cloud","text":"function handles process writing data parquet file uploading cloud storage.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_parquet_to_cloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload Processed Data to Cloud Storage — upload_parquet_to_cloud","text":"","code":"upload_parquet_to_cloud(   data,   prefix,   provider,   options,   compression = \"lz4\",   compression_level = 12 )"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_parquet_to_cloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload Processed Data to Cloud Storage — upload_parquet_to_cloud","text":"data data frame tibble upload prefix file prefix path cloud storage provider cloud storage provider key options Cloud storage provider options compression Compression algorithm use (default: \"lz4\") compression_level Compression level (default: 12)","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_parquet_to_cloud.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upload Processed Data to Cloud Storage — upload_parquet_to_cloud","text":"Invisible NULL","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/upload_parquet_to_cloud.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upload Processed Data to Cloud Storage — upload_parquet_to_cloud","text":"","code":"if (FALSE) { # \\dontrun{ upload_parquet_to_cloud(   data = processed_data,   prefix = conf$ingestion$koboform$catch$legacy$preprocessed,   provider = conf$storage$google$key,   options = conf$storage$google$options ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_ba_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Blue Alliance (BA) Surveys Data — validate_ba_surveys","title":"Validate Blue Alliance (BA) Surveys Data — validate_ba_surveys","text":"Validates Blue Alliance survey data performing quality checks calculating catch metrics. function follows main steps: Loads preprocesses survey data Performs logical checks key variables Calculates catch length bounds Flags potential data quality issues Saves uploads validated data","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_ba_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Blue Alliance (BA) Surveys Data — validate_ba_surveys","text":"","code":"validate_ba_surveys(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_ba_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Blue Alliance (BA) Surveys Data — validate_ba_surveys","text":"log_threshold logging level threshold logger package (e.g., DEBUG, INFO)","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_ba_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Blue Alliance (BA) Surveys Data — validate_ba_surveys","text":"None. Writes validated data parquet file uploads cloud storage","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_ba_surveys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate Blue Alliance (BA) Surveys Data — validate_ba_surveys","text":"validation includes: Logical checks (non-negative catches, valid fisher counts, valid trip durations) Statistical outlier detection catch weights lengths Automated flagging system quality control Alert flag descriptions: 1: Total catch negative 2: Number fishers 0 negative 3: Trip duration 0 negative 4: Catch weight length exceeds calculated bounds","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_catches.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate catches using quality flags — validate_catches","title":"Validate catches using quality flags — validate_catches","text":"Applies validation flags filters problematic catches based quality checks. Propagates flags survey level ensure consistency.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_catches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate catches using quality flags — validate_catches","text":"","code":"validate_catches(catch_data)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_catches.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate catches using quality flags — validate_catches","text":"catch_data Processed catch data","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_catches.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate catches using quality flags — validate_catches","text":"dataframe validated catches","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_prices.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate market prices — validate_prices","title":"Validate market prices — validate_prices","text":"Processes validates market price data, filtering reasonable price ranges calculating median prices species group family. Processes validates market price data, filtering reasonable price ranges calculating median prices species group family.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_prices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate market prices — validate_prices","text":"","code":"validate_prices(preprocessed_data)  validate_prices(preprocessed_data)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_prices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate market prices — validate_prices","text":"preprocessed_data Preprocessed survey data containing market information","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_prices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate market prices — validate_prices","text":"dataframe validated market prices dataframe validated market prices","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wcs_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate WCS Surveys Data — validate_wcs_surveys","title":"Validate WCS Surveys Data — validate_wcs_surveys","text":"Validates Wildlife Conservation Society (WCS) survey data performing quality checks calculating catch metrics. function follows main steps: Preprocesses survey data Validates catches using predefined thresholds weights, counts prices Calculates revenue CPUE metrics Uploads validated data cloud storage","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wcs_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate WCS Surveys Data — validate_wcs_surveys","text":"","code":"validate_wcs_surveys(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wcs_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate WCS Surveys Data — validate_wcs_surveys","text":"log_threshold logging level threshold logger package (e.g., DEBUG, INFO)","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wcs_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate WCS Surveys Data — validate_wcs_surveys","text":"None. Writes validated data parquet file uploads cloud storage","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wcs_surveys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate WCS Surveys Data — validate_wcs_surveys","text":"validation includes: Basic data quality checks (e.g., negative catches, missing values) Gear-specific validations (e.g., number fishers per gear type) Weight thresholds catch type (individual vs bucket measures) Market price validations (valid price ranges per kg)","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wf_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Wild Fishing Survey Data — validate_wf_surveys","title":"Validate Wild Fishing Survey Data — validate_wf_surveys","text":"Validates survey data wild fishing activities applying quality control checks flagging potential data issues. function filters submissions meet validation criteria processes catch data.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wf_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Wild Fishing Survey Data — validate_wf_surveys","text":"","code":"validate_wf_surveys(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wf_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Wild Fishing Survey Data — validate_wf_surveys","text":"log_threshold logging level threshold logger package (e.g., DEBUG, INFO)","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wf_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Wild Fishing Survey Data — validate_wf_surveys","text":"function processes uploads two datasets cloud storage: Validation flags submission Validated survey data invalid submissions removed","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wf_surveys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate Wild Fishing Survey Data — validate_wf_surveys","text":"function applies following validation checks: Bucket weight validation (max 50 kg per bucket) Number buckets validation (max 300 buckets) Number individuals validation (max 100 individuals) Form completeness check catch details Catch information completeness check Alert codes: 5: Bucket weight exceeds maximum 6: Number buckets exceeds maximum 7: Number individuals exceeds maximum 8: Incomplete catch form 9: Incomplete catch information","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wf_surveys.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Validate Wild Fishing Survey Data — validate_wf_surveys","text":"Requires configuration parameters set config file Automatically downloads preprocessed survey data cloud storage Removes submissions fail validation checks Sets catch_kg 0 catch_outcome 0","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/reference/validate_wf_surveys.html","id":"data-processing-steps","dir":"Reference","previous_headings":"","what":"Data Processing Steps","title":"Validate Wild Fishing Survey Data — validate_wf_surveys","text":"Downloads preprocessed survey data Applies validation checks generates alert flags Filters submissions validation alerts Processes catch data adjusts catch weights Uploads validation flags validated data cloud storage","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"major-changes-2-4-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"peskas.zanzibar.data.pipeline 2.4.0","text":"Refactored get_validated_surveys() handle WCS, WF, BA sources Added source parameter specify datasets retrieve Improved handling data sources different column structures","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"new-features-2-4-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"peskas.zanzibar.data.pipeline 2.4.0","text":"Added export_wf_data() function WorldFish-specific data export Price per kg validation CPUE (Catch Per Unit Effort) validation RPUE (Revenue Per Unit Effort) validation","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"improvements-2-4-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"peskas.zanzibar.data.pipeline 2.4.0","text":"Added min_length parameter better length validation thresholds Updated LW coefficient filtering logic model-taxa.R Enhanced alert flag handling combined flags different validation steps Improved catch price catch weight handling zero-catch outcomes Enhanced data preprocessing better field type conversion","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"bug-fixes-2-4-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"peskas.zanzibar.data.pipeline 2.4.0","text":"Fixed issue catch_price field type WF survey preprocessing Corrected filter condition taxa coefficients","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"major-changes-2-3-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"peskas.zanzibar.data.pipeline 2.3.0","text":"Implemented new validation status retrieval KoboToolbox API Updated validation workflow incorporate submission validation status Improved data validation process direct API integration","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"new-features-2-3-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"peskas.zanzibar.data.pipeline 2.3.0","text":"get_validation_status(): Retrieves submission validation status KoboToolbox API","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"improvements-2-3-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"peskas.zanzibar.data.pipeline 2.3.0","text":"Modified configuration files support new KoboToolbox API token Added new environment variable KoboToolbox API authentication Enhanced validation workflow integrated validation status checks","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"major-changes-2-2-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"peskas.zanzibar.data.pipeline 2.2.0","text":"Introduced new modular functions taxa handling model-taxa.R Added efficient batch processing species matching Implemented optimized FAO area retrieval system Streamlined length-weight coefficient calculations Enhanced integration FishBase SeaLifeBase","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"new-features-2-2-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"peskas.zanzibar.data.pipeline 2.2.0","text":"load_taxa_databases(): Unified database loading FishBase SeaLifeBase process_species_list(): Enhanced species list processing taxonomic ranks match_species_from_taxa(): Improved species matching across databases get_species_areas_batch(): Efficient FAO area retrieval get_length_weight_batch(): Optimized length-weight parameter retrieval","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"improvements-2-2-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"peskas.zanzibar.data.pipeline 2.2.0","text":"Enhanced performance batch processing Reduced API calls external databases Better error handling input validation comprehensive documentation Improved code organization modularity","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"deprecations-2-2-0","dir":"Changelog","previous_headings":"","what":"Deprecations","title":"peskas.zanzibar.data.pipeline 2.2.0","text":"Removed legacy taxonomic processing functions Deprecated redundant species matching methods Removed outdated data transformation utilities","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"documentation-2-2-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"peskas.zanzibar.data.pipeline 2.2.0","text":"Added detailed function documentation Updated vignettes new workflows Improved code examples Enhanced README new features","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"major-changes-2-1-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"peskas.zanzibar.data.pipeline 2.1.0","text":"Added comprehensive functions species catch data processing Implemented length-weight coefficient retrieval FishBase SeaLifeBase Created functions calculating catch weights using multiple methods Added new data reshaping utilities species catch information Extended Wild Fishing (WF) survey validation detailed quality checks Updated cloud storage data download/upload functions","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"major-changes-2-0-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"peskas.zanzibar.data.pipeline 2.0.0","text":"Complete overhaul data pipeline architecture New trip ingestion preprocessing functionality GPS track data processing capabilities Implemented MongoDB export storage functions Removed renv dependency management improved reliability Updated Docker configuration robust builds","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"new-features-2-0-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"peskas.zanzibar.data.pipeline 2.0.0","text":"Enhanced validation system survey data GPS track preprocessing Catch data validation Length measurements validation Market data validation Flexible data export capabilities Improved GitHub Actions workflow additional processing steps","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"infrastructure-updates-2-0-0","dir":"Changelog","previous_headings":"","what":"Infrastructure Updates","title":"peskas.zanzibar.data.pipeline 2.0.0","text":"Streamlined package dependencies Updated build deployment processes Enhanced data storage retrieval mechanisms","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"improvements-1-0-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"peskas.zanzibar.data.pipeline 1.0.0","text":"functions now documented indexed according keywords Thin R folder gathering functions modules","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"peskas.zanzibar.data.pipeline 1.0.0","text":"Move parquet format rather CSV/RDS","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"new-features-0-2-0","dir":"Changelog","previous_headings":"","what":"New features","title":"peskas.zanzibar.data.pipeline 0.2.0","text":"Added validation step updated preprocessing step wcs kobo surveys data, see preprocess_wcs_surveys() validate_wcs_surveys() functions. Currently, validation catch weight, length market values obtained using median absolute deviation method (MAD) leveraging k parameters univOutl::LocScaleB function. order accurately spot outliers, validation performed based gear type species. N.B. VALIDATION PARAMETERS YET TUNED","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"peskas.zanzibar.data.pipeline 0.2.0","text":"need run pipeline every two days, decreased every 4 days.","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"peskaszanzibardatapipeline-010","dir":"Changelog","previous_headings":"","what":"peskas.zanzibar.data.pipeline 0.1.0","title":"peskas.zanzibar.data.pipeline 0.1.0","text":"Drop parent repository code (peskas.timor.pipeline), add infrastructure download WCS survey data upload cloud storage providers","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"new-features-0-1-0","dir":"Changelog","previous_headings":"","what":"New features","title":"peskas.zanzibar.data.pipeline 0.1.0","text":"ingestion WCS Zanzibar surveys implemented ingest_wcs_surveys(). functions retrieve_wcs_surveys() downloads WCS Zanzibar surveys data","code":""},{"path":"https://worldfishcenter.github.io/peskas.zanzibar.data.pipeline/news/index.html","id":"changes-0-1-0","dir":"Changelog","previous_headings":"New features","what":"Changes","title":"peskas.zanzibar.data.pipeline 0.1.0","text":"Moved configuration settings inst/conf.yml Improved configuration structure organization Enhanced configuration flexibility","code":""}]
